{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbadc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. Import Necessary Libraries\n",
    "# ============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib  # For saving models\n",
    "from tqdm import tqdm  # For progress bars\n",
    "\n",
    "# ============================\n",
    "# 2. Set Random Seed\n",
    "# ============================\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ============================\n",
    "# 3. Load and Inspect Data\n",
    "# ============================\n",
    "\n",
    "# Read the dataset\n",
    "data_path = 'path_to_your_data.csv'  # Replace with your actual file path\n",
    "data_df = pd.read_csv(data_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "print(data_df.info())\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"\\nFirst 5 Rows of the Dataset:\")\n",
    "print(data_df.head())\n",
    "\n",
    "# ============================\n",
    "# 4. Data Preprocessing\n",
    "# ============================\n",
    "\n",
    "# Assume the last column is the target variable (adjust if necessary)\n",
    "feature_cols = data_df.columns[:-1]\n",
    "target_col = data_df.columns[-1]\n",
    "\n",
    "X = data_df[feature_cols].values\n",
    "y = data_df[target_col].values\n",
    "\n",
    "# Check for missing values\n",
    "if np.isnan(X).any() or np.isnan(y).any():\n",
    "    print(\"Missing values detected. Performing imputation...\")\n",
    "    # Simple imputation: Replace NaNs with the mean of each column\n",
    "    X = np.nan_to_num(X, nan=np.nanmean(X))\n",
    "    y = np.nan_to_num(y, nan=np.nanmean(y))\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print(\"\\nData Preprocessing Completed.\")\n",
    "\n",
    "# ============================\n",
    "# 5. Define Model and Hyperparameter Search Space\n",
    "# ============================\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "search_space = {\n",
    "    'model': ['LinearRegression', 'Ridge', 'Lasso', 'ElasticNet'],\n",
    "    'alpha': [0.1, 1.0, 10.0],  # Applicable to Ridge, Lasso, ElasticNet\n",
    "    'l1_ratio': [0.2, 0.5, 0.8],  # Applicable to ElasticNet\n",
    "}\n",
    "\n",
    "# Generate hyperparameter combinations\n",
    "param_grid = []\n",
    "for model in search_space['model']:\n",
    "    if model == 'LinearRegression':\n",
    "        param_grid.append({'model': [model]})\n",
    "    elif model in ['Ridge', 'Lasso']:\n",
    "        param_grid.append({'model': [model], 'alpha': search_space['alpha']})\n",
    "    elif model == 'ElasticNet':\n",
    "        param_grid.append({'model': [model], 'alpha': search_space['alpha'], 'l1_ratio': search_space['l1_ratio']})\n",
    "\n",
    "# ============================\n",
    "# 6. Five-Fold Cross-Validation and Model Training\n",
    "# ============================\n",
    "\n",
    "# Initialize K-Fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize list to store results for each hyperparameter combination\n",
    "all_results = []\n",
    "\n",
    "print(\"Starting five-fold cross-validation and hyperparameter search...\\n\")\n",
    "\n",
    "# Iterate over each hyperparameter combination\n",
    "for params in tqdm(param_grid, desc=\"Model Combinations\"):\n",
    "    # Initialize metrics storage for current hyperparameter combination\n",
    "    fold_metrics = {\n",
    "        'train_mae': [],\n",
    "        'train_mse': [],\n",
    "        'train_rmse': [],\n",
    "        'train_r2': [],\n",
    "        'val_mae': [],\n",
    "        'val_mse': [],\n",
    "        'val_rmse': [],\n",
    "        'val_r2': []\n",
    "    }\n",
    "    \n",
    "    # Iterate over each fold\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        # Select and initialize the model based on hyperparameters\n",
    "        if params['model'] == 'LinearRegression':\n",
    "            model = LinearRegression()\n",
    "        elif params['model'] == 'Ridge':\n",
    "            model = Ridge(alpha=params['alpha'])\n",
    "        elif params['model'] == 'Lasso':\n",
    "            model = Lasso(alpha=params['alpha'])\n",
    "        elif params['model'] == 'ElasticNet':\n",
    "            model = ElasticNet(alpha=params['alpha'], l1_ratio=params['l1_ratio'])\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {params['model']}\")\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions on training set\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        train_rmse = np.sqrt(train_mse)\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        \n",
    "        # Predictions on validation set\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "        val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "        val_rmse = np.sqrt(val_mse)\n",
    "        val_r2 = r2_score(y_val, y_val_pred)\n",
    "        \n",
    "        # Store metrics for the current fold\n",
    "        fold_metrics['train_mae'].append(train_mae)\n",
    "        fold_metrics['train_mse'].append(train_mse)\n",
    "        fold_metrics['train_rmse'].append(train_rmse)\n",
    "        fold_metrics['train_r2'].append(train_r2)\n",
    "        fold_metrics['val_mae'].append(val_mae)\n",
    "        fold_metrics['val_mse'].append(val_mse)\n",
    "        fold_metrics['val_rmse'].append(val_rmse)\n",
    "        fold_metrics['val_r2'].append(val_r2)\n",
    "    \n",
    "    # Calculate average metrics across all folds for the current hyperparameter combination\n",
    "    avg_metrics = {metric: np.mean(values) for metric, values in fold_metrics.items()}\n",
    "    avg_metrics['params'] = params\n",
    "    all_results.append(avg_metrics)\n",
    "\n",
    "# ============================\n",
    "# 7. Results Analysis and Saving\n",
    "# ============================\n",
    "\n",
    "# Convert all results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Sort the results based on validation R² in descending order and select the top 10\n",
    "top_results = results_df.sort_values(by='val_r2', ascending=False).head(10)\n",
    "print(\"\\nTop 10 Hyperparameter Combinations Based on Average Validation R²:\")\n",
    "print(top_results[['params', 'val_r2']])\n",
    "\n",
    "# Save all results to an Excel file for further analysis\n",
    "results_df.to_excel('LR_Model_AllResults.xlsx', index=False)\n",
    "print(\"\\nAll hyperparameter search results have been saved to 'LR_Model_AllResults.xlsx'\")\n",
    "\n",
    "# ============================\n",
    "# 8. Extract Best Hyperparameter Combination\n",
    "# ============================\n",
    "\n",
    "# Extract the hyperparameter combination with the highest validation R²\n",
    "best_result = results_df.loc[results_df['val_r2'].idxmax()]\n",
    "best_params = best_result['params']\n",
    "print(f\"\\nBest Hyperparameter Combination: {best_params}\")\n",
    "\n",
    "# ============================\n",
    "# 9. Train Final Model with Best Hyperparameters\n",
    "# ============================\n",
    "\n",
    "# Initialize and train the final model using the best hyperparameters on the entire dataset\n",
    "if best_params['model'] == 'LinearRegression':\n",
    "    final_model = LinearRegression()\n",
    "elif best_params['model'] == 'Ridge':\n",
    "    final_model = Ridge(alpha=best_params['alpha'])\n",
    "elif best_params['model'] == 'Lasso':\n",
    "    final_model = Lasso(alpha=best_params['alpha'])\n",
    "elif best_params['model'] == 'ElasticNet':\n",
    "    final_model = ElasticNet(alpha=best_params['alpha'], l1_ratio=best_params['l1_ratio'])\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported model: {best_params['model']}\")\n",
    "\n",
    "# Train the final model on the entire dataset\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "y_pred = final_model.predict(X)\n",
    "\n",
    "# Calculate performance metrics\n",
    "final_mae = mean_absolute_error(y, y_pred)\n",
    "final_mse = mean_squared_error(y, y_pred)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(\"\\nFinal Model Performance on the Entire Dataset:\")\n",
    "print(f\"MAE: {final_mae:.4f}\")\n",
    "print(f\"MSE: {final_mse:.4f}\")\n",
    "print(f\"RMSE: {final_rmse:.4f}\")\n",
    "print(f\"R²: {final_r2:.4f}\")\n",
    "\n",
    "# ============================\n",
    "# 10. Save the Best Model\n",
    "# ============================\n",
    "\n",
    "# Save the scaler and the final trained model using joblib\n",
    "joblib.dump(scaler, 'LR_Scaler.pkl')\n",
    "joblib.dump(final_model, 'LR_FinalModel.pkl')\n",
    "print(\"\\nScaler and final model have been saved.\")\n",
    "\n",
    "# ============================\n",
    "# 11. Save Best Hyperparameters and Final Results\n",
    "# ============================\n",
    "\n",
    "# Save the best hyperparameters and final performance metrics to an Excel file\n",
    "results_to_save = {\n",
    "    'Best Params': [best_params],\n",
    "    'Final MAE': [final_mae],\n",
    "    'Final MSE': [final_mse],\n",
    "    'Final RMSE': [final_rmse],\n",
    "    'Final R²': [final_r2]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_summary = pd.DataFrame(results_to_save)\n",
    "\n",
    "# Save to Excel\n",
    "results_summary.to_excel('LR_Model_BestResults.xlsx', index=False)\n",
    "print(\"\\nBest model results have been saved to 'LR_Model_BestResults.xlsx'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN2",
   "language": "python",
   "name": "gnn2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
